{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 21 : Computer Vision**\n",
        "---\n",
        "\n",
        "### **Description**\n",
        "Last week, we used a CNN to build a \"Chihuahua or Muffin\" image classifier. In many CV applications, we are working with a small amount of data for our task, which can make deep learning difficult. In today's lab, we will explore two methods for addressing a lack of data: **data augmentation** and **transfer learning.**\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Lab Structure**\n",
        "**Part 1**: Alpaca or Not Alpaca?\n",
        "> **Part 1.1**: Build an Image Classifier CNN with Data Augmentation in keras\n",
        "\n",
        "> **Part 1.2**: Use a Pre-Trained Model\n",
        "\n",
        "**Part 2**: Car Camera Image Segmentation [OPTIONAL]\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "**NOTE:** For this lab, it is really important that you **change your runtime type to GPU**. To do this, follow these steps:\n",
        "* Navigate to \"Runtime\" at the toolbar at the top\n",
        "* Select \"Change runtime type\"\n",
        "* Under \"Hardware accelerator\", select \"GPU\" (if it already is GPU, you don't need to do anything)\n",
        "* Save\n",
        "\n",
        "You may need to reconnect to runtime after this, there will be a button \"Connect\" or \"Reconnect\" at the top right corner of the screen. If you see a RAM/Disk icon, you do not need to do anything.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Goals** \n",
        "By the end of this lab, you will:\n",
        "* Know how to use `keras` to augment your dataset\n",
        "* Understand how to use a pre-trained model\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Cheat Sheets**\n",
        "[Deep Learning with Data Augmentation Cheat Sheet](https://docs.google.com/document/d/15a1TH8L6c0qRr_pMByjDfMAog74zTTHxDFyJO4BBA-8/edit?usp=sharing)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Before starting, run the code below to import all necessary functions and libraries.**\n"
      ],
      "metadata": {
        "id": "mbZXQ3rA3NwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip install --quiet gdown==4.5.4 --no-cache-dir\n",
        "!pip install --quiet tensorflow==2.8.3\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.optimizers import *\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "from keras.metrics import *\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, Lambda\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import keras.layers as tfl\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation"
      ],
      "metadata": {
        "id": "YAvvLhRIoqYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Part 1**\n",
        "---\n",
        "\n",
        "**Alpaca or Not Alpaca?** Today, we will build another image classifier with a CNN, but we will incorporate data augmentation. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HQ6FDZAEsGPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Steps of making a neural network**\n",
        "\n",
        "1. Import and split the data into a train/test set\n",
        "2. Determine the dimensions of the data\n",
        "3. Initialize the network model\n",
        "4. Add an input layer\n",
        "5. Add the hidden layers\n",
        "6. Add the output layer\n",
        "7. Fit the model\n",
        "8. Evaluate the model\n",
        "\n",
        "**We will follow these steps again today, but expand Step #3 to add data augmentation after initializing the network.**"
      ],
      "metadata": {
        "id": "5ph_GKALoqBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Part #1.1: Building a CNN with Data Augmentation**\n",
        "---\n"
      ],
      "metadata": {
        "id": "TkFdnCApsGPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step #1: Import and split the data into a train/test set**\n",
        "---\n",
        "\n",
        "**Together**, we will import, pre-process the data, and split it into a training and validation set. We will use the validation set to help us improve the model in the next section. \n",
        "\n",
        "<br>\n",
        "\n",
        "The first step is to import and pre-process the data."
      ],
      "metadata": {
        "id": "EQjyoGNUsGPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1Dc9qpV80dgZcFzxw_n3Rx8adsnAM_P1d && unzip -qq alpaca_not_alpaca.zip"
      ],
      "metadata": {
        "id": "YHdEcuKhu3Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remember that the batch size is the number of images that will be processed \n",
        "# the model is updated. One epoch is one full pass through the dataset.\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Size of the images. If the input images are a different size, they will be \n",
        "# resized to these dimensions.\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "# Directory the data is saved.\n",
        "directory = \"dataset/\"\n",
        "\n",
        "# We are using keras's image_dataset_from_directory function to load the images\n",
        "# from the directory. When we use this function, we can tell keras if it is a\n",
        "# validation or training set. Just make sure to use the same seed for both to\n",
        "# make sure there is no overlap in the datasets.\n",
        "train_dataset = image_dataset_from_directory(directory,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE,\n",
        "                                             validation_split=0.2,\n",
        "                                             subset='training',\n",
        "                                             seed=42)\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(directory,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE,\n",
        "                                             validation_split=0.2,\n",
        "                                             subset='validation',\n",
        "                                             seed=42)"
      ],
      "metadata": {
        "id": "P20yNOiRvAww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the names of each class from the dataset. In this case, the class is\n",
        "# \"alpaca\" or \"not alpaca\"\n",
        "class_names = train_dataset.class_names\n",
        "\n",
        "# We'll take 9 images from the training dataset to plot\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "KmKzZpGhvAwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step #2: Defining the input shape of the data**\n",
        "---"
      ],
      "metadata": {
        "id": "jTgRZUWMtgV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem #1.1:** Define the input shape for the model. Remember we set the image size to 160x160 pixels."
      ],
      "metadata": {
        "id": "5KYKYrvrvFgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape for the model\n",
        "input_shape = "
      ],
      "metadata": {
        "id": "x8ZaETV8ubiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step #3-6: Building the Neural Network with Data Augmentation**\n",
        "---\n"
      ],
      "metadata": {
        "id": "t2WyNKf5u86l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation in keras is easy to implement. We can add special layers to our model that will do the augmentation for us. We just specify what kind of augmentation we want to do. In this case, we'll randomly flip some images horizontally and randomly rotate some as well. \n",
        "\n",
        "The layers we will use are:\n",
        "* `RandomFlip('horizontal')` (we could also choose vertical or both)\n",
        "* `RandomRotation(0.2)` (the input here is the rotation angle in radians)\n",
        "\n",
        "\n",
        "Just to see how this works, we'll set up a model that does data augmentation and nothing else. \n",
        "\n",
        "*This code has been provided for you. Just run the cell below.*"
      ],
      "metadata": {
        "id": "eUrNsof7wcmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model normally\n",
        "model_DA = Sequential()\n",
        "\n",
        "# Add a layer that will add a random horizontal flip to the data\n",
        "model_DA.add(RandomFlip('horizontal'))\n",
        "\n",
        "# Add a layer that will randomly rotate the data\n",
        "model_DA.add(RandomRotation(0.2))"
      ],
      "metadata": {
        "id": "lEFsue-lwcma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the result of applying data augmentation. Do not worry about the syntax here, this is just for demonstration. \n",
        "\n",
        "*The code below is provided for you. Just run the cell below.*"
      ],
      "metadata": {
        "id": "TE96PmTSwcmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image, _ in train_dataset.take(1):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    first_image = image[0]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        augmented_image = model_DA(tf.expand_dims(first_image, 0))\n",
        "        plt.imshow(augmented_image[0] / 255)\n",
        "        plt.axis('off')"
      ],
      "metadata": {
        "id": "L1O_1kHJwcmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we're ready to build our CNN!"
      ],
      "metadata": {
        "id": "GCfpnkvSxYzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem #1.2:** Initialize a sequential neural network and add the two data augmentation layers as shown above."
      ],
      "metadata": {
        "id": "lqQw8z0mvJd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = \n",
        "\n",
        "# Add a layer that will add a random horizontal flip to the data\n",
        "\n",
        "\n",
        "# Add a layer that will randomly rotate the data\n"
      ],
      "metadata": {
        "id": "6_WP2Hw3vOBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's all! Now, we can build the rest of our CNN as we would normally. \n",
        "\n"
      ],
      "metadata": {
        "id": "BPSpvIE_ve8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem #1.3:** Together, build a CNN with the following layers:\n",
        "\n",
        "* A convolutional layer with 32 filters, filter size of (3,3), and ReLU activation. Make sure to pass the input shape as a parameter.\n",
        "* A max pooling layer with a pool size of (2,2)\n",
        "* A convolutional layer with 64 filters, filter size of (3,3), and ReLU activation.\n",
        "* A max pooling layer with a pool size of (2,2)\n",
        "* A flatten layer\n",
        "* A dense layer with 256 neurons and ReLU activation\n",
        "* An output layer\n"
      ],
      "metadata": {
        "id": "Aj879vX-HHV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the first convolutional layer\n",
        "\n",
        "\n",
        "# Add a max pooling layer\n",
        "\n",
        "\n",
        "# Add the second convolutional layer\n",
        "\n",
        "\n",
        "# Add a max pooling layer\n",
        "\n",
        "\n",
        "# Flatten the output from the convolutional layers\n",
        "\n",
        "\n",
        "# Add a fully connected layer\n",
        "\n",
        "\n",
        "# Add the output layer\n"
      ],
      "metadata": {
        "id": "MzaAquA3FoVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Solution**"
      ],
      "metadata": {
        "id": "BKNdoPc6Ha7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the first convolutional layer\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "\n",
        "# Add a max pooling layer\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Add the second convolutional layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Add a max pooling layer\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the output from the convolutional layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a fully connected layer\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "m5AYQbWmHck2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the model summary."
      ],
      "metadata": {
        "id": "xnGqJjLDOfTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "O_qTtNhVMlOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step #7: Training the Neural Network**\n",
        "\n",
        "---\n",
        "\n",
        "Next, we will compile the network. We will use the same loss function, optimizer, and metric as last time.\n",
        "\n",
        "*This code is provided for you. Just run the cell below.*"
      ],
      "metadata": {
        "id": "2a4u2qS_QHgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset, \n",
        "    validation_data=validation_dataset, \n",
        "    epochs=10)"
      ],
      "metadata": {
        "id": "uZuVV9wZz4uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step #8: Evaluate the Model**\n",
        "---\n",
        "Let's see if the model was able to accurately classify whether each image was an alpaca or not.\n",
        "\n",
        "*This code is provided for you. Just run the cells below.*"
      ],
      "metadata": {
        "id": "H9SocsxSSt9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = [0.] + history.history['accuracy']\n",
        "val_acc = [0.] + history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,5.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5XNa7bOwT1Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll take 9 images from the validation dataset to plot\n",
        "plt.figure(figsize=(15, 15))\n",
        "for x, y in validation_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        prediction = model.predict(x)[i]\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
        "        tmp2 = \"predicted {:.0f}% alpaca, actually \".format(100*(1-prediction[0]), fontsize=14)\n",
        "        plt.title(tmp2 + class_names[y[i].numpy()])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "iBJygLoc0K2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, our CNN isn't doing so well! Thankfully, for small data sets, there's a better way."
      ],
      "metadata": {
        "id": "z-3rX0oF3jRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "#### **Back to lecture**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "oOB_s6qx1fAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Part #1.2: Using a Pre-Trained Model**\n",
        "---\n",
        "\n",
        "One way to improve our model would be to train it on more data. Unfortunately, we don't always have access to more data. In this part we will use **transfer learning** which means we will use a model that has been previously trained on a large dataset and modify it for our needs. Today, we will use the VGG16 model, which is a CNN with 16 layers that has been trained on the ImageNet dataset. \n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "We are going to use the same data as before, we will just define and use a new model."
      ],
      "metadata": {
        "id": "OgvzN47sq0oa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Steps #3-6: Build a new neural network using a pre-trained model**\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LgxeGdrG1O5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "new_model = Sequential()\n",
        "\n",
        "# Add input layer \n",
        "new_model.add(Input(shape=input_shape))\n",
        "\n",
        "# Add data augmentation layers\n",
        "new_model.add(RandomFlip('horizontal'))\n",
        "new_model.add(RandomRotation(0.2))\n",
        "\n",
        "# You do not need to worry about this step. But in case you are curious:\n",
        "# The \"Lambda\" layer is another special layer that lets you apply a custom \n",
        "# function to the data. Because we know we're going to use VGG16, we will use \n",
        "# the same pre-processing function that was used when it was first trained.\n",
        "new_model.add(\n",
        "    Lambda(\n",
        "        preprocess_input,\n",
        "        name='preprocessing', \n",
        "        input_shape=input_shape\n",
        "    )\n",
        ")\n",
        "\n",
        "# Load a pre-trained model\n",
        "VGG = VGG16(\n",
        "    # we want to use our own final layers customized for our task\n",
        "    include_top=False, \n",
        "    input_shape=input_shape,\n",
        "    weights='imagenet'\n",
        "    )\n",
        "\n",
        "# Freeze parameters each layer because we only want to train the final layers\n",
        "for layer in VGG.layers: \n",
        "  layer.trainable = False\n",
        "\n",
        "# Add the pre-trained model to our model\n",
        "new_model.add(VGG)\n",
        "\n",
        "# Add a flattening layer\n",
        "new_model.add(Flatten())\n",
        "\n",
        "# Add a fully connected layer\n",
        "new_model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "new_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "new_model.summary()\n"
      ],
      "metadata": {
        "id": "bRsGbmBvzdlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = new_model.fit(\n",
        "    train_dataset, \n",
        "    validation_data=validation_dataset, \n",
        "    epochs=10)"
      ],
      "metadata": {
        "id": "nZAj462i1cMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = [0.] + history.history['accuracy']\n",
        "val_acc = [0.] + history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "42k3CcYK1nKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll take 9 images from the validation dataset to plot\n",
        "plt.figure(figsize=(15, 15))\n",
        "for x, y in validation_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        prediction = new_model.predict(x)[i]\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
        "        tmp2 = \"predicted {:.0f}% alpaca, actually \".format(100*(1-prediction[0]), fontsize=14)\n",
        "        plt.title(tmp2 + class_names[y[i].numpy()])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "x10cskXimI6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "#### **Back to lecture**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0EOWYdxhTiki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Before continuing to Part 2, run this cell below for necessary imports. {display-mode: \"form\"}\n",
        "\n",
        "\n",
        "!pip install --quiet git+https://github.com/divamgupta/image-segmentation-keras\n",
        "!wget --quiet https://github.com/divamgupta/datasets/releases/download/seg/dataset1.zip && unzip -qq dataset1.zip\n",
        "\n",
        "from keras_segmentation.models.unet import vgg_unet"
      ],
      "metadata": {
        "id": "_n9axGg82ACF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvDIuw6vlsKN"
      },
      "source": [
        "---\n",
        "## **Part 2: Car Camera Image Segmentation**\n",
        "---\n",
        "\n",
        "Below, we have provided code for you to see image segmentation in action. This task was accomplished using a pre-trained **U-Net** model, which is a special kind of CNN developed for biomedical image segmentation. \n",
        "\n",
        "Just run the code below to see the result. It may take a few minutes. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The image we are going to segment\n",
        "Image(\"dataset1/images_prepped_test/0016E5_07965.png\")"
      ],
      "metadata": {
        "id": "bfOiaUR36mLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the code is provided for you. Just run the cell below. This may take several minutes to run."
      ],
      "metadata": {
        "id": "S4J8aHkT5cvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = vgg_unet(n_classes=50, input_height=320, input_width=640)\n",
        "\n",
        "model.train(\n",
        "    train_images =  \"dataset1/images_prepped_train/\",\n",
        "    train_annotations = \"dataset1/annotations_prepped_train/\",\n",
        "    checkpoints_path = \"/tmp/vgg_unet_1\",\n",
        "    epochs=5  \n",
        ")\n",
        "\n",
        "output = model.predict_segmentation(\n",
        "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
        "    out_fname=\"/tmp/out.png\", overlay_img=True, show_legends=True,\n",
        "    class_names = [ \"Sky\", \"Building\", \"Pole\", \"Road\", \"Pavement\", \"Tree\", \"SignSymbol\", \"Fence\", \"Car\", \"Pedestrian\", \"Bicyclist\"]\n",
        "\n",
        ")\n",
        "\n",
        "Image('/tmp/out.png')"
      ],
      "metadata": {
        "id": "kl-vxZOO-rxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "#### **Back to lecture**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VomeZDEQm2iq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#End of notebook\n",
        "---\n",
        "© 2023 The Coding School, All rights reserved"
      ],
      "metadata": {
        "id": "7dzC09dLlEhm"
      }
    }
  ]
}